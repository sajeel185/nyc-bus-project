{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import ensemble\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "import geopy.distance\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datetime import timedelta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (14,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordedAtTime</th>\n",
       "      <th>DirectionRef</th>\n",
       "      <th>PublishedLineName</th>\n",
       "      <th>OriginName</th>\n",
       "      <th>OriginLat</th>\n",
       "      <th>OriginLong</th>\n",
       "      <th>DestinationName</th>\n",
       "      <th>DestinationLat</th>\n",
       "      <th>DestinationLong</th>\n",
       "      <th>VehicleRef</th>\n",
       "      <th>VehicleLocation.Latitude</th>\n",
       "      <th>VehicleLocation.Longitude</th>\n",
       "      <th>NextStopPointName</th>\n",
       "      <th>ArrivalProximityText</th>\n",
       "      <th>DistanceFromStop</th>\n",
       "      <th>ExpectedArrivalTime</th>\n",
       "      <th>ScheduledArrivalTime</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>B8</td>\n",
       "      <td>4 AV/95 ST</td>\n",
       "      <td>40.616104</td>\n",
       "      <td>-74.031143</td>\n",
       "      <td>BROWNSVILLE ROCKAWAY AV</td>\n",
       "      <td>40.656048</td>\n",
       "      <td>-73.907379</td>\n",
       "      <td>NYCT_430</td>\n",
       "      <td>40.635170</td>\n",
       "      <td>-73.960803</td>\n",
       "      <td>FOSTER AV/E 18 ST</td>\n",
       "      <td>approaching</td>\n",
       "      <td>76</td>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>24:06:14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>1</td>\n",
       "      <td>S61</td>\n",
       "      <td>ST GEORGE FERRY/S61 &amp; S91</td>\n",
       "      <td>40.643169</td>\n",
       "      <td>-74.073494</td>\n",
       "      <td>S I MALL YUKON AV</td>\n",
       "      <td>40.575935</td>\n",
       "      <td>-74.167686</td>\n",
       "      <td>NYCT_8263</td>\n",
       "      <td>40.590802</td>\n",
       "      <td>-74.158340</td>\n",
       "      <td>MERRYMOUNT ST/TRAVIS AV</td>\n",
       "      <td>approaching</td>\n",
       "      <td>62</td>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>23:58:02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>Bx10</td>\n",
       "      <td>E 206 ST/BAINBRIDGE AV</td>\n",
       "      <td>40.875008</td>\n",
       "      <td>-73.880142</td>\n",
       "      <td>RIVERDALE 263 ST</td>\n",
       "      <td>40.912376</td>\n",
       "      <td>-73.902534</td>\n",
       "      <td>NYCT_4223</td>\n",
       "      <td>40.886010</td>\n",
       "      <td>-73.912647</td>\n",
       "      <td>HENRY HUDSON PKY E/W 235 ST</td>\n",
       "      <td>at stop</td>\n",
       "      <td>5</td>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>24:00:53</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>Q5</td>\n",
       "      <td>TEARDROP/LAYOVER</td>\n",
       "      <td>40.701748</td>\n",
       "      <td>-73.802399</td>\n",
       "      <td>ROSEDALE LIRR STA via MERRICK</td>\n",
       "      <td>40.666012</td>\n",
       "      <td>-73.735939</td>\n",
       "      <td>NYCT_8422</td>\n",
       "      <td>40.668002</td>\n",
       "      <td>-73.729348</td>\n",
       "      <td>HOOK CREEK BL/SUNRISE HY</td>\n",
       "      <td>&lt; 1 stop away</td>\n",
       "      <td>267</td>\n",
       "      <td>6/1/2017 0:04</td>\n",
       "      <td>24:03:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>1</td>\n",
       "      <td>Bx1</td>\n",
       "      <td>RIVERDALE AV/W 231 ST</td>\n",
       "      <td>40.881187</td>\n",
       "      <td>-73.909340</td>\n",
       "      <td>MOTT HAVEN 136 ST via CONCOURSE</td>\n",
       "      <td>40.809654</td>\n",
       "      <td>-73.928360</td>\n",
       "      <td>NYCT_4710</td>\n",
       "      <td>40.868134</td>\n",
       "      <td>-73.893032</td>\n",
       "      <td>GRAND CONCOURSE/E 196 ST</td>\n",
       "      <td>at stop</td>\n",
       "      <td>11</td>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>23:59:38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RecordedAtTime  DirectionRef PublishedLineName                 OriginName  \\\n",
       "0  6/1/2017 0:03             0                B8                 4 AV/95 ST   \n",
       "1  6/1/2017 0:03             1               S61  ST GEORGE FERRY/S61 & S91   \n",
       "2  6/1/2017 0:03             0              Bx10     E 206 ST/BAINBRIDGE AV   \n",
       "3  6/1/2017 0:03             0                Q5           TEARDROP/LAYOVER   \n",
       "4  6/1/2017 0:03             1               Bx1      RIVERDALE AV/W 231 ST   \n",
       "\n",
       "   OriginLat  OriginLong                  DestinationName  DestinationLat  \\\n",
       "0  40.616104  -74.031143          BROWNSVILLE ROCKAWAY AV       40.656048   \n",
       "1  40.643169  -74.073494                S I MALL YUKON AV       40.575935   \n",
       "2  40.875008  -73.880142                 RIVERDALE 263 ST       40.912376   \n",
       "3  40.701748  -73.802399    ROSEDALE LIRR STA via MERRICK       40.666012   \n",
       "4  40.881187  -73.909340  MOTT HAVEN 136 ST via CONCOURSE       40.809654   \n",
       "\n",
       "   DestinationLong VehicleRef  VehicleLocation.Latitude  \\\n",
       "0       -73.907379   NYCT_430                 40.635170   \n",
       "1       -74.167686  NYCT_8263                 40.590802   \n",
       "2       -73.902534  NYCT_4223                 40.886010   \n",
       "3       -73.735939  NYCT_8422                 40.668002   \n",
       "4       -73.928360  NYCT_4710                 40.868134   \n",
       "\n",
       "   VehicleLocation.Longitude            NextStopPointName  \\\n",
       "0                 -73.960803            FOSTER AV/E 18 ST   \n",
       "1                 -74.158340      MERRYMOUNT ST/TRAVIS AV   \n",
       "2                 -73.912647  HENRY HUDSON PKY E/W 235 ST   \n",
       "3                 -73.729348     HOOK CREEK BL/SUNRISE HY   \n",
       "4                 -73.893032     GRAND CONCOURSE/E 196 ST   \n",
       "\n",
       "  ArrivalProximityText DistanceFromStop ExpectedArrivalTime  \\\n",
       "0          approaching               76       6/1/2017 0:03   \n",
       "1          approaching               62       6/1/2017 0:03   \n",
       "2              at stop                5       6/1/2017 0:03   \n",
       "3        < 1 stop away              267       6/1/2017 0:04   \n",
       "4              at stop               11       6/1/2017 0:03   \n",
       "\n",
       "  ScheduledArrivalTime Unnamed: 17  \n",
       "0             24:06:14         NaN  \n",
       "1             23:58:02         NaN  \n",
       "2             24:00:53         NaN  \n",
       "3             24:03:00         NaN  \n",
       "4             23:59:38         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('nyc bus data.csv')\n",
    "df = df.drop_duplicates()\n",
    "# = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset the dataframe to include only the first 100,000 rows, or observations.\n",
    "#df = df.iloc[:700000, :]\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 18 columns):\n",
      "RecordedAtTime               1048575 non-null object\n",
      "DirectionRef                 1048575 non-null int64\n",
      "PublishedLineName            1048575 non-null object\n",
      "OriginName                   1040112 non-null object\n",
      "OriginLat                    1040112 non-null float64\n",
      "OriginLong                   1040112 non-null float64\n",
      "DestinationName              1048575 non-null object\n",
      "DestinationLat               1047329 non-null float64\n",
      "DestinationLong              1047329 non-null float64\n",
      "VehicleRef                   1048575 non-null object\n",
      "VehicleLocation.Latitude     1048575 non-null float64\n",
      "VehicleLocation.Longitude    1048575 non-null float64\n",
      "NextStopPointName            1047439 non-null object\n",
      "ArrivalProximityText         1047439 non-null object\n",
      "DistanceFromStop             1047439 non-null object\n",
      "ExpectedArrivalTime          931342 non-null object\n",
      "ScheduledArrivalTime         1022903 non-null object\n",
      "Unnamed: 17                  59 non-null object\n",
      "dtypes: float64(6), int64(1), object(11)\n",
      "memory usage: 152.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#checking for column types and missing data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling in missing data \n",
    "df['OriginName'].ffill(axis=0, inplace=True)\n",
    "df['OriginLat'].ffill(axis=0, inplace=True)\n",
    "df['OriginLong'].ffill(axis=0, inplace=True)\n",
    "df['DestinationLat'].ffill(axis=0, inplace=True)\n",
    "df['DestinationLong'].ffill(axis=0, inplace=True)\n",
    "df['DistanceFromStop'].ffill(axis=0, inplace=True)\n",
    "df['ArrivalProximityText'].ffill(axis=0, inplace=True)\n",
    "df['NextStopPointName'].ffill(axis=0, inplace=True)\n",
    "df['ExpectedArrivalTime'].ffill(axis=0, inplace=True)\n",
    "df['ScheduledArrivalTime'].ffill(axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0     1\n",
      "0  6/1/2017  0:03\n",
      "1  6/1/2017  0:03\n",
      "2  6/1/2017  0:03\n",
      "3  6/1/2017  0:04\n",
      "4  6/1/2017  0:03\n"
     ]
    }
   ],
   "source": [
    "#splitting 'ExpectedArrivalTime' column\n",
    "expected_split = df['ExpectedArrivalTime'].str.split(expand=True)\n",
    "print(expected_split.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new feature; the 'expected_date' column\n",
    "df['expected_date'] = expected_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatting the 'ScheduledArrivalTime'\n",
    "df['ScheduledArrivalTime'] = df['ScheduledArrivalTime'].apply(lambda x: x[0:2].replace('24', '00')) + df['ScheduledArrivalTime'].apply(lambda x: x[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    00:06:14\n",
       "1    23:58:02\n",
       "2    00:00:53\n",
       "3    00:03:00\n",
       "4    23:59:38\n",
       "Name: ScheduledArrivalTime, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examining the 'ScheduledArrivalTime' column\n",
    "df['ScheduledArrivalTime'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new feature'Scheduled_datetime' column\n",
    "df['Scheduled_datetime'] = df['expected_date'] + ' ' + df['ScheduledArrivalTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6/1/2017 00:06:14\n",
       "1    6/1/2017 23:58:02\n",
       "2    6/1/2017 00:00:53\n",
       "3    6/1/2017 00:03:00\n",
       "4    6/1/2017 23:59:38\n",
       "Name: Scheduled_datetime, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examining 'Scheduled_datetime' column\n",
    "df['Scheduled_datetime'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting 'Scheduled_datetime' to datetime object\n",
    "df['Scheduled_datetime'] = pd.to_datetime(df['Scheduled_datetime'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting 'Expected_arrival' column to datetime object\n",
    "df['Expected_datetime'] = pd.to_datetime(df['ExpectedArrivalTime'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 21 columns):\n",
      "RecordedAtTime               1048575 non-null object\n",
      "DirectionRef                 1048575 non-null int64\n",
      "PublishedLineName            1048575 non-null object\n",
      "OriginName                   1048575 non-null object\n",
      "OriginLat                    1048575 non-null float64\n",
      "OriginLong                   1048575 non-null float64\n",
      "DestinationName              1048575 non-null object\n",
      "DestinationLat               1048575 non-null float64\n",
      "DestinationLong              1048575 non-null float64\n",
      "VehicleRef                   1048575 non-null object\n",
      "VehicleLocation.Latitude     1048575 non-null float64\n",
      "VehicleLocation.Longitude    1048575 non-null float64\n",
      "NextStopPointName            1048575 non-null object\n",
      "ArrivalProximityText         1048575 non-null object\n",
      "DistanceFromStop             1048575 non-null object\n",
      "ExpectedArrivalTime          1048575 non-null object\n",
      "ScheduledArrivalTime         1048575 non-null object\n",
      "Unnamed: 17                  59 non-null object\n",
      "expected_date                1048575 non-null object\n",
      "Scheduled_datetime           1041552 non-null datetime64[ns]\n",
      "Expected_datetime            1048507 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(6), int64(1), object(12)\n",
      "memory usage: 176.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling in missing data\n",
    "df['Scheduled_datetime'].ffill(axis=0, inplace=True)\n",
    "df['Expected_datetime'].ffill(axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048516"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above null values are in the \"Unnamed\" column, which I will drop later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing the date value for those datetime entries where the hour is near midnight.\n",
    "df['Scheduled_datetime'] = df['Scheduled_datetime'].apply(lambda x: x - timedelta(days=1) if str(x)[11:13] == '23' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new feature to record the difference between each bus's scheduled arrival time and expected arrival time.\n",
    "df['delay'] = df['Expected_datetime'] - df['Scheduled_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordedAtTime</th>\n",
       "      <th>DirectionRef</th>\n",
       "      <th>PublishedLineName</th>\n",
       "      <th>OriginName</th>\n",
       "      <th>OriginLat</th>\n",
       "      <th>OriginLong</th>\n",
       "      <th>DestinationName</th>\n",
       "      <th>DestinationLat</th>\n",
       "      <th>DestinationLong</th>\n",
       "      <th>VehicleRef</th>\n",
       "      <th>...</th>\n",
       "      <th>NextStopPointName</th>\n",
       "      <th>ArrivalProximityText</th>\n",
       "      <th>DistanceFromStop</th>\n",
       "      <th>ExpectedArrivalTime</th>\n",
       "      <th>ScheduledArrivalTime</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>expected_date</th>\n",
       "      <th>Scheduled_datetime</th>\n",
       "      <th>Expected_datetime</th>\n",
       "      <th>delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>B8</td>\n",
       "      <td>4 AV/95 ST</td>\n",
       "      <td>40.616104</td>\n",
       "      <td>-74.031143</td>\n",
       "      <td>BROWNSVILLE ROCKAWAY AV</td>\n",
       "      <td>40.656048</td>\n",
       "      <td>-73.907379</td>\n",
       "      <td>NYCT_430</td>\n",
       "      <td>...</td>\n",
       "      <td>FOSTER AV/E 18 ST</td>\n",
       "      <td>approaching</td>\n",
       "      <td>76</td>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>00:06:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:06:14</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>-1 days +23:56:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>1</td>\n",
       "      <td>S61</td>\n",
       "      <td>ST GEORGE FERRY/S61 &amp; S91</td>\n",
       "      <td>40.643169</td>\n",
       "      <td>-74.073494</td>\n",
       "      <td>S I MALL YUKON AV</td>\n",
       "      <td>40.575935</td>\n",
       "      <td>-74.167686</td>\n",
       "      <td>NYCT_8263</td>\n",
       "      <td>...</td>\n",
       "      <td>MERRYMOUNT ST/TRAVIS AV</td>\n",
       "      <td>approaching</td>\n",
       "      <td>62</td>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>23:58:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-05-31 23:58:02</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>00:04:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>Bx10</td>\n",
       "      <td>E 206 ST/BAINBRIDGE AV</td>\n",
       "      <td>40.875008</td>\n",
       "      <td>-73.880142</td>\n",
       "      <td>RIVERDALE 263 ST</td>\n",
       "      <td>40.912376</td>\n",
       "      <td>-73.902534</td>\n",
       "      <td>NYCT_4223</td>\n",
       "      <td>...</td>\n",
       "      <td>HENRY HUDSON PKY E/W 235 ST</td>\n",
       "      <td>at stop</td>\n",
       "      <td>5</td>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>00:00:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:00:53</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>00:02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>Q5</td>\n",
       "      <td>TEARDROP/LAYOVER</td>\n",
       "      <td>40.701748</td>\n",
       "      <td>-73.802399</td>\n",
       "      <td>ROSEDALE LIRR STA via MERRICK</td>\n",
       "      <td>40.666012</td>\n",
       "      <td>-73.735939</td>\n",
       "      <td>NYCT_8422</td>\n",
       "      <td>...</td>\n",
       "      <td>HOOK CREEK BL/SUNRISE HY</td>\n",
       "      <td>&lt; 1 stop away</td>\n",
       "      <td>267</td>\n",
       "      <td>6/1/2017 0:04</td>\n",
       "      <td>00:03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>2017-06-01 00:04:00</td>\n",
       "      <td>00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>1</td>\n",
       "      <td>Bx1</td>\n",
       "      <td>RIVERDALE AV/W 231 ST</td>\n",
       "      <td>40.881187</td>\n",
       "      <td>-73.909340</td>\n",
       "      <td>MOTT HAVEN 136 ST via CONCOURSE</td>\n",
       "      <td>40.809654</td>\n",
       "      <td>-73.928360</td>\n",
       "      <td>NYCT_4710</td>\n",
       "      <td>...</td>\n",
       "      <td>GRAND CONCOURSE/E 196 ST</td>\n",
       "      <td>at stop</td>\n",
       "      <td>11</td>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>23:59:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-05-31 23:59:38</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>00:03:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  RecordedAtTime  DirectionRef PublishedLineName                 OriginName  \\\n",
       "0  6/1/2017 0:03             0                B8                 4 AV/95 ST   \n",
       "1  6/1/2017 0:03             1               S61  ST GEORGE FERRY/S61 & S91   \n",
       "2  6/1/2017 0:03             0              Bx10     E 206 ST/BAINBRIDGE AV   \n",
       "3  6/1/2017 0:03             0                Q5           TEARDROP/LAYOVER   \n",
       "4  6/1/2017 0:03             1               Bx1      RIVERDALE AV/W 231 ST   \n",
       "\n",
       "   OriginLat  OriginLong                  DestinationName  DestinationLat  \\\n",
       "0  40.616104  -74.031143          BROWNSVILLE ROCKAWAY AV       40.656048   \n",
       "1  40.643169  -74.073494                S I MALL YUKON AV       40.575935   \n",
       "2  40.875008  -73.880142                 RIVERDALE 263 ST       40.912376   \n",
       "3  40.701748  -73.802399    ROSEDALE LIRR STA via MERRICK       40.666012   \n",
       "4  40.881187  -73.909340  MOTT HAVEN 136 ST via CONCOURSE       40.809654   \n",
       "\n",
       "   DestinationLong VehicleRef        ...                   NextStopPointName  \\\n",
       "0       -73.907379   NYCT_430        ...                   FOSTER AV/E 18 ST   \n",
       "1       -74.167686  NYCT_8263        ...             MERRYMOUNT ST/TRAVIS AV   \n",
       "2       -73.902534  NYCT_4223        ...         HENRY HUDSON PKY E/W 235 ST   \n",
       "3       -73.735939  NYCT_8422        ...            HOOK CREEK BL/SUNRISE HY   \n",
       "4       -73.928360  NYCT_4710        ...            GRAND CONCOURSE/E 196 ST   \n",
       "\n",
       "   ArrivalProximityText DistanceFromStop ExpectedArrivalTime  \\\n",
       "0           approaching               76       6/1/2017 0:03   \n",
       "1           approaching               62       6/1/2017 0:03   \n",
       "2               at stop                5       6/1/2017 0:03   \n",
       "3         < 1 stop away              267       6/1/2017 0:04   \n",
       "4               at stop               11       6/1/2017 0:03   \n",
       "\n",
       "  ScheduledArrivalTime Unnamed: 17 expected_date  Scheduled_datetime  \\\n",
       "0             00:06:14         NaN      6/1/2017 2017-06-01 00:06:14   \n",
       "1             23:58:02         NaN      6/1/2017 2017-05-31 23:58:02   \n",
       "2             00:00:53         NaN      6/1/2017 2017-06-01 00:00:53   \n",
       "3             00:03:00         NaN      6/1/2017 2017-06-01 00:03:00   \n",
       "4             23:59:38         NaN      6/1/2017 2017-05-31 23:59:38   \n",
       "\n",
       "    Expected_datetime             delay  \n",
       "0 2017-06-01 00:03:00 -1 days +23:56:46  \n",
       "1 2017-06-01 00:03:00          00:04:58  \n",
       "2 2017-06-01 00:03:00          00:02:07  \n",
       "3 2017-06-01 00:04:00          00:01:00  \n",
       "4 2017-06-01 00:03:00          00:03:22  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new feature called 'HourOfDay', to reflect relationship of the time of day and whether or not a bus is on time.\n",
    "df['Scheduled_HourOfDay'] = df['Scheduled_datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new feature \"delay_second\" to equate 'delay' column in seconds\n",
    "df['delay_second'] = df['delay'].dt.seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new feature 'delay_minute' to convert the delay_second to minutes\n",
    "df['delay_minute'] = df['delay_second'] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new feature delay_days by extracting the day value from 'delay' column\n",
    "df['delay_days'] = df['delay'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordedAtTime</th>\n",
       "      <th>DirectionRef</th>\n",
       "      <th>PublishedLineName</th>\n",
       "      <th>OriginName</th>\n",
       "      <th>OriginLat</th>\n",
       "      <th>OriginLong</th>\n",
       "      <th>DestinationName</th>\n",
       "      <th>DestinationLat</th>\n",
       "      <th>DestinationLong</th>\n",
       "      <th>VehicleRef</th>\n",
       "      <th>...</th>\n",
       "      <th>ScheduledArrivalTime</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>expected_date</th>\n",
       "      <th>Scheduled_datetime</th>\n",
       "      <th>Expected_datetime</th>\n",
       "      <th>delay</th>\n",
       "      <th>Scheduled_HourOfDay</th>\n",
       "      <th>delay_second</th>\n",
       "      <th>delay_minute</th>\n",
       "      <th>delay_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>B8</td>\n",
       "      <td>4 AV/95 ST</td>\n",
       "      <td>40.616104</td>\n",
       "      <td>-74.031143</td>\n",
       "      <td>BROWNSVILLE ROCKAWAY AV</td>\n",
       "      <td>40.656048</td>\n",
       "      <td>-73.907379</td>\n",
       "      <td>NYCT_430</td>\n",
       "      <td>...</td>\n",
       "      <td>00:06:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:06:14</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>-1 days +23:56:46</td>\n",
       "      <td>0</td>\n",
       "      <td>86206</td>\n",
       "      <td>1436.766667</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>1</td>\n",
       "      <td>S61</td>\n",
       "      <td>ST GEORGE FERRY/S61 &amp; S91</td>\n",
       "      <td>40.643169</td>\n",
       "      <td>-74.073494</td>\n",
       "      <td>S I MALL YUKON AV</td>\n",
       "      <td>40.575935</td>\n",
       "      <td>-74.167686</td>\n",
       "      <td>NYCT_8263</td>\n",
       "      <td>...</td>\n",
       "      <td>23:58:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-05-31 23:58:02</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>00:04:58</td>\n",
       "      <td>23</td>\n",
       "      <td>298</td>\n",
       "      <td>4.966667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>Bx10</td>\n",
       "      <td>E 206 ST/BAINBRIDGE AV</td>\n",
       "      <td>40.875008</td>\n",
       "      <td>-73.880142</td>\n",
       "      <td>RIVERDALE 263 ST</td>\n",
       "      <td>40.912376</td>\n",
       "      <td>-73.902534</td>\n",
       "      <td>NYCT_4223</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:00:53</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>00:02:07</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>2.116667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>Q5</td>\n",
       "      <td>TEARDROP/LAYOVER</td>\n",
       "      <td>40.701748</td>\n",
       "      <td>-73.802399</td>\n",
       "      <td>ROSEDALE LIRR STA via MERRICK</td>\n",
       "      <td>40.666012</td>\n",
       "      <td>-73.735939</td>\n",
       "      <td>NYCT_8422</td>\n",
       "      <td>...</td>\n",
       "      <td>00:03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>2017-06-01 00:04:00</td>\n",
       "      <td>00:01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>1</td>\n",
       "      <td>Bx1</td>\n",
       "      <td>RIVERDALE AV/W 231 ST</td>\n",
       "      <td>40.881187</td>\n",
       "      <td>-73.909340</td>\n",
       "      <td>MOTT HAVEN 136 ST via CONCOURSE</td>\n",
       "      <td>40.809654</td>\n",
       "      <td>-73.928360</td>\n",
       "      <td>NYCT_4710</td>\n",
       "      <td>...</td>\n",
       "      <td>23:59:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-05-31 23:59:38</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>00:03:22</td>\n",
       "      <td>23</td>\n",
       "      <td>202</td>\n",
       "      <td>3.366667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  RecordedAtTime  DirectionRef PublishedLineName                 OriginName  \\\n",
       "0  6/1/2017 0:03             0                B8                 4 AV/95 ST   \n",
       "1  6/1/2017 0:03             1               S61  ST GEORGE FERRY/S61 & S91   \n",
       "2  6/1/2017 0:03             0              Bx10     E 206 ST/BAINBRIDGE AV   \n",
       "3  6/1/2017 0:03             0                Q5           TEARDROP/LAYOVER   \n",
       "4  6/1/2017 0:03             1               Bx1      RIVERDALE AV/W 231 ST   \n",
       "\n",
       "   OriginLat  OriginLong                  DestinationName  DestinationLat  \\\n",
       "0  40.616104  -74.031143          BROWNSVILLE ROCKAWAY AV       40.656048   \n",
       "1  40.643169  -74.073494                S I MALL YUKON AV       40.575935   \n",
       "2  40.875008  -73.880142                 RIVERDALE 263 ST       40.912376   \n",
       "3  40.701748  -73.802399    ROSEDALE LIRR STA via MERRICK       40.666012   \n",
       "4  40.881187  -73.909340  MOTT HAVEN 136 ST via CONCOURSE       40.809654   \n",
       "\n",
       "   DestinationLong VehicleRef    ...      ScheduledArrivalTime  Unnamed: 17  \\\n",
       "0       -73.907379   NYCT_430    ...                  00:06:14          NaN   \n",
       "1       -74.167686  NYCT_8263    ...                  23:58:02          NaN   \n",
       "2       -73.902534  NYCT_4223    ...                  00:00:53          NaN   \n",
       "3       -73.735939  NYCT_8422    ...                  00:03:00          NaN   \n",
       "4       -73.928360  NYCT_4710    ...                  23:59:38          NaN   \n",
       "\n",
       "  expected_date  Scheduled_datetime   Expected_datetime             delay  \\\n",
       "0      6/1/2017 2017-06-01 00:06:14 2017-06-01 00:03:00 -1 days +23:56:46   \n",
       "1      6/1/2017 2017-05-31 23:58:02 2017-06-01 00:03:00          00:04:58   \n",
       "2      6/1/2017 2017-06-01 00:00:53 2017-06-01 00:03:00          00:02:07   \n",
       "3      6/1/2017 2017-06-01 00:03:00 2017-06-01 00:04:00          00:01:00   \n",
       "4      6/1/2017 2017-05-31 23:59:38 2017-06-01 00:03:00          00:03:22   \n",
       "\n",
       "  Scheduled_HourOfDay delay_second delay_minute delay_days  \n",
       "0                   0        86206  1436.766667         -1  \n",
       "1                  23          298     4.966667          0  \n",
       "2                   0          127     2.116667          0  \n",
       "3                   0           60     1.000000          0  \n",
       "4                  23          202     3.366667          0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 26 columns):\n",
      "RecordedAtTime               1048575 non-null object\n",
      "DirectionRef                 1048575 non-null int64\n",
      "PublishedLineName            1048575 non-null object\n",
      "OriginName                   1048575 non-null object\n",
      "OriginLat                    1048575 non-null float64\n",
      "OriginLong                   1048575 non-null float64\n",
      "DestinationName              1048575 non-null object\n",
      "DestinationLat               1048575 non-null float64\n",
      "DestinationLong              1048575 non-null float64\n",
      "VehicleRef                   1048575 non-null object\n",
      "VehicleLocation.Latitude     1048575 non-null float64\n",
      "VehicleLocation.Longitude    1048575 non-null float64\n",
      "NextStopPointName            1048575 non-null object\n",
      "ArrivalProximityText         1048575 non-null object\n",
      "DistanceFromStop             1048575 non-null object\n",
      "ExpectedArrivalTime          1048575 non-null object\n",
      "ScheduledArrivalTime         1048575 non-null object\n",
      "Unnamed: 17                  59 non-null object\n",
      "expected_date                1048575 non-null object\n",
      "Scheduled_datetime           1048575 non-null datetime64[ns]\n",
      "Expected_datetime            1048575 non-null datetime64[ns]\n",
      "delay                        1048575 non-null timedelta64[ns]\n",
      "Scheduled_HourOfDay          1048575 non-null int64\n",
      "delay_second                 1048575 non-null int64\n",
      "delay_minute                 1048575 non-null float64\n",
      "delay_days                   1048575 non-null int64\n",
      "dtypes: datetime64[ns](2), float64(7), int64(4), object(12), timedelta64[ns](1)\n",
      "memory usage: 216.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring dataframe where \"delay_days\" equals zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering the original dataset\n",
    "df_zero = df[df['delay_days'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordedAtTime</th>\n",
       "      <th>DirectionRef</th>\n",
       "      <th>PublishedLineName</th>\n",
       "      <th>OriginName</th>\n",
       "      <th>OriginLat</th>\n",
       "      <th>OriginLong</th>\n",
       "      <th>DestinationName</th>\n",
       "      <th>DestinationLat</th>\n",
       "      <th>DestinationLong</th>\n",
       "      <th>VehicleRef</th>\n",
       "      <th>...</th>\n",
       "      <th>ScheduledArrivalTime</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>expected_date</th>\n",
       "      <th>Scheduled_datetime</th>\n",
       "      <th>Expected_datetime</th>\n",
       "      <th>delay</th>\n",
       "      <th>Scheduled_HourOfDay</th>\n",
       "      <th>delay_second</th>\n",
       "      <th>delay_minute</th>\n",
       "      <th>delay_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>1</td>\n",
       "      <td>S61</td>\n",
       "      <td>ST GEORGE FERRY/S61 &amp; S91</td>\n",
       "      <td>40.643169</td>\n",
       "      <td>-74.073494</td>\n",
       "      <td>S I MALL YUKON AV</td>\n",
       "      <td>40.575935</td>\n",
       "      <td>-74.167686</td>\n",
       "      <td>NYCT_8263</td>\n",
       "      <td>...</td>\n",
       "      <td>23:58:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-05-31 23:58:02</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>00:04:58</td>\n",
       "      <td>23</td>\n",
       "      <td>298</td>\n",
       "      <td>4.966667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>Bx10</td>\n",
       "      <td>E 206 ST/BAINBRIDGE AV</td>\n",
       "      <td>40.875008</td>\n",
       "      <td>-73.880142</td>\n",
       "      <td>RIVERDALE 263 ST</td>\n",
       "      <td>40.912376</td>\n",
       "      <td>-73.902534</td>\n",
       "      <td>NYCT_4223</td>\n",
       "      <td>...</td>\n",
       "      <td>00:00:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:00:53</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>00:02:07</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>2.116667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>Q5</td>\n",
       "      <td>TEARDROP/LAYOVER</td>\n",
       "      <td>40.701748</td>\n",
       "      <td>-73.802399</td>\n",
       "      <td>ROSEDALE LIRR STA via MERRICK</td>\n",
       "      <td>40.666012</td>\n",
       "      <td>-73.735939</td>\n",
       "      <td>NYCT_8422</td>\n",
       "      <td>...</td>\n",
       "      <td>00:03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>2017-06-01 00:04:00</td>\n",
       "      <td>00:01:00</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>1</td>\n",
       "      <td>Bx1</td>\n",
       "      <td>RIVERDALE AV/W 231 ST</td>\n",
       "      <td>40.881187</td>\n",
       "      <td>-73.909340</td>\n",
       "      <td>MOTT HAVEN 136 ST via CONCOURSE</td>\n",
       "      <td>40.809654</td>\n",
       "      <td>-73.928360</td>\n",
       "      <td>NYCT_4710</td>\n",
       "      <td>...</td>\n",
       "      <td>23:59:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-05-31 23:59:38</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>00:03:22</td>\n",
       "      <td>23</td>\n",
       "      <td>202</td>\n",
       "      <td>3.366667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>M1</td>\n",
       "      <td>4 AV/E 10 ST</td>\n",
       "      <td>40.731342</td>\n",
       "      <td>-73.990288</td>\n",
       "      <td>HARLEM 147 ST via MADISON</td>\n",
       "      <td>40.821110</td>\n",
       "      <td>-73.935898</td>\n",
       "      <td>NYCT_3831</td>\n",
       "      <td>...</td>\n",
       "      <td>00:02:35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:02:35</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>00:00:25</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  RecordedAtTime  DirectionRef PublishedLineName                 OriginName  \\\n",
       "1  6/1/2017 0:03             1               S61  ST GEORGE FERRY/S61 & S91   \n",
       "2  6/1/2017 0:03             0              Bx10     E 206 ST/BAINBRIDGE AV   \n",
       "3  6/1/2017 0:03             0                Q5           TEARDROP/LAYOVER   \n",
       "4  6/1/2017 0:03             1               Bx1      RIVERDALE AV/W 231 ST   \n",
       "5  6/1/2017 0:03             0                M1               4 AV/E 10 ST   \n",
       "\n",
       "   OriginLat  OriginLong                  DestinationName  DestinationLat  \\\n",
       "1  40.643169  -74.073494                S I MALL YUKON AV       40.575935   \n",
       "2  40.875008  -73.880142                 RIVERDALE 263 ST       40.912376   \n",
       "3  40.701748  -73.802399    ROSEDALE LIRR STA via MERRICK       40.666012   \n",
       "4  40.881187  -73.909340  MOTT HAVEN 136 ST via CONCOURSE       40.809654   \n",
       "5  40.731342  -73.990288        HARLEM 147 ST via MADISON       40.821110   \n",
       "\n",
       "   DestinationLong VehicleRef    ...      ScheduledArrivalTime  Unnamed: 17  \\\n",
       "1       -74.167686  NYCT_8263    ...                  23:58:02          NaN   \n",
       "2       -73.902534  NYCT_4223    ...                  00:00:53          NaN   \n",
       "3       -73.735939  NYCT_8422    ...                  00:03:00          NaN   \n",
       "4       -73.928360  NYCT_4710    ...                  23:59:38          NaN   \n",
       "5       -73.935898  NYCT_3831    ...                  00:02:35          NaN   \n",
       "\n",
       "  expected_date  Scheduled_datetime   Expected_datetime    delay  \\\n",
       "1      6/1/2017 2017-05-31 23:58:02 2017-06-01 00:03:00 00:04:58   \n",
       "2      6/1/2017 2017-06-01 00:00:53 2017-06-01 00:03:00 00:02:07   \n",
       "3      6/1/2017 2017-06-01 00:03:00 2017-06-01 00:04:00 00:01:00   \n",
       "4      6/1/2017 2017-05-31 23:59:38 2017-06-01 00:03:00 00:03:22   \n",
       "5      6/1/2017 2017-06-01 00:02:35 2017-06-01 00:03:00 00:00:25   \n",
       "\n",
       "  Scheduled_HourOfDay delay_second delay_minute delay_days  \n",
       "1                  23          298     4.966667          0  \n",
       "2                   0          127     2.116667          0  \n",
       "3                   0           60     1.000000          0  \n",
       "4                  23          202     3.366667          0  \n",
       "5                   0           25     0.416667          0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zero.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017-06-02    187562\n",
       "2017-06-01    176890\n",
       "2017-06-05    161573\n",
       "2017-06-03    132538\n",
       "2017-06-04    104490\n",
       "2017-05-31      1509\n",
       "Name: Scheduled_datetime, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#value counts of the dates in scheduled datetime\n",
    "df_zero.Scheduled_datetime.dt.date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017-06-02    187434\n",
       "2017-06-01    177178\n",
       "2017-06-05    162137\n",
       "2017-06-03    132419\n",
       "2017-06-04    105394\n",
       "Name: Expected_datetime, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#value_counts of the dates in Expected datetime\n",
    "df_zero.Expected_datetime.dt.date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "00:01:00    21215\n",
       "00:00:00    20973\n",
       "00:02:00    19748\n",
       "00:03:00    17457\n",
       "00:04:00    15582\n",
       "00:05:00    13712\n",
       "00:06:00    12310\n",
       "00:07:00    10952\n",
       "00:08:00     9878\n",
       "00:09:00     8917\n",
       "00:10:00     7993\n",
       "00:11:00     7055\n",
       "00:12:00     6291\n",
       "00:13:00     5477\n",
       "00:14:00     4953\n",
       "00:15:00     4187\n",
       "00:16:00     3671\n",
       "00:17:00     3111\n",
       "00:18:00     2872\n",
       "00:19:00     2403\n",
       "00:12:02     2121\n",
       "00:20:00     2113\n",
       "00:21:00     1884\n",
       "00:06:40     1718\n",
       "00:22:00     1661\n",
       "00:22:12     1582\n",
       "00:36:00     1567\n",
       "00:23:00     1519\n",
       "00:24:00     1402\n",
       "00:00:52     1230\n",
       "            ...  \n",
       "01:04:49        1\n",
       "23:55:07        1\n",
       "01:03:37        1\n",
       "03:13:00        1\n",
       "00:55:18        1\n",
       "23:25:00        1\n",
       "23:55:37        1\n",
       "23:30:47        1\n",
       "01:09:54        1\n",
       "01:14:38        1\n",
       "01:21:54        1\n",
       "00:54:09        1\n",
       "00:57:12        1\n",
       "23:52:43        1\n",
       "01:34:00        1\n",
       "00:47:03        1\n",
       "01:45:00        1\n",
       "00:53:34        1\n",
       "23:55:14        1\n",
       "01:11:58        1\n",
       "01:20:05        1\n",
       "23:32:43        1\n",
       "23:54:23        1\n",
       "01:10:36        1\n",
       "23:45:26        1\n",
       "01:49:10        1\n",
       "01:12:19        1\n",
       "01:15:57        1\n",
       "00:53:56        1\n",
       "01:02:36        1\n",
       "Name: delay, Length: 5025, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zero.delay.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the dataset where \"delay_days\" equals -1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering the original dataset for only those observations where 'delay_days' equals -1\n",
    "df_neg1 = df[df['delay_days'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordedAtTime</th>\n",
       "      <th>DirectionRef</th>\n",
       "      <th>PublishedLineName</th>\n",
       "      <th>OriginName</th>\n",
       "      <th>OriginLat</th>\n",
       "      <th>OriginLong</th>\n",
       "      <th>DestinationName</th>\n",
       "      <th>DestinationLat</th>\n",
       "      <th>DestinationLong</th>\n",
       "      <th>VehicleRef</th>\n",
       "      <th>...</th>\n",
       "      <th>ScheduledArrivalTime</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>expected_date</th>\n",
       "      <th>Scheduled_datetime</th>\n",
       "      <th>Expected_datetime</th>\n",
       "      <th>delay</th>\n",
       "      <th>Scheduled_HourOfDay</th>\n",
       "      <th>delay_second</th>\n",
       "      <th>delay_minute</th>\n",
       "      <th>delay_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>B8</td>\n",
       "      <td>4 AV/95 ST</td>\n",
       "      <td>40.616104</td>\n",
       "      <td>-74.031143</td>\n",
       "      <td>BROWNSVILLE ROCKAWAY AV</td>\n",
       "      <td>40.656048</td>\n",
       "      <td>-73.907379</td>\n",
       "      <td>NYCT_430</td>\n",
       "      <td>...</td>\n",
       "      <td>00:06:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:06:14</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>-1 days +23:56:46</td>\n",
       "      <td>0</td>\n",
       "      <td>86206</td>\n",
       "      <td>1436.766667</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>B31</td>\n",
       "      <td>GERRITSEN AV/GERRITSEN BEACH</td>\n",
       "      <td>40.587101</td>\n",
       "      <td>-73.918503</td>\n",
       "      <td>MIDWOOD KINGS HWY STA</td>\n",
       "      <td>40.608433</td>\n",
       "      <td>-73.957100</td>\n",
       "      <td>NYCT_4611</td>\n",
       "      <td>...</td>\n",
       "      <td>00:08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:08:00</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>-1 days +23:55:00</td>\n",
       "      <td>0</td>\n",
       "      <td>86100</td>\n",
       "      <td>1435.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>87 ST/4 Av</td>\n",
       "      <td>40.621925</td>\n",
       "      <td>-74.028496</td>\n",
       "      <td>MANHATTAN BEACH KINGSBORO CC</td>\n",
       "      <td>40.578094</td>\n",
       "      <td>-73.940170</td>\n",
       "      <td>NYCT_7141</td>\n",
       "      <td>...</td>\n",
       "      <td>00:05:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:05:55</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>-1 days +23:57:05</td>\n",
       "      <td>0</td>\n",
       "      <td>86225</td>\n",
       "      <td>1437.083333</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>1</td>\n",
       "      <td>B26</td>\n",
       "      <td>WYCKOFF ST/PALMETTO ST</td>\n",
       "      <td>40.699150</td>\n",
       "      <td>-73.910477</td>\n",
       "      <td>DNTWN BKLYN TILLARY ST via HALSEY</td>\n",
       "      <td>40.693939</td>\n",
       "      <td>-73.990311</td>\n",
       "      <td>NYCT_6503</td>\n",
       "      <td>...</td>\n",
       "      <td>00:05:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:05:55</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>-1 days +23:57:05</td>\n",
       "      <td>0</td>\n",
       "      <td>86225</td>\n",
       "      <td>1437.083333</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>Bx39</td>\n",
       "      <td>SOUNDVIEW AV/STEPHENS AV</td>\n",
       "      <td>40.807869</td>\n",
       "      <td>-73.852715</td>\n",
       "      <td>WAKEFIELD 241 ST via WHITE PLS RD</td>\n",
       "      <td>40.903309</td>\n",
       "      <td>-73.849922</td>\n",
       "      <td>NYCT_4723</td>\n",
       "      <td>...</td>\n",
       "      <td>00:04:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:04:12</td>\n",
       "      <td>2017-06-01 00:04:00</td>\n",
       "      <td>-1 days +23:59:48</td>\n",
       "      <td>0</td>\n",
       "      <td>86388</td>\n",
       "      <td>1439.800000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordedAtTime  DirectionRef PublishedLineName  \\\n",
       "0   6/1/2017 0:03             0                B8   \n",
       "6   6/1/2017 0:03             0               B31   \n",
       "11  6/1/2017 0:03             1                B1   \n",
       "12  6/1/2017 0:03             1               B26   \n",
       "13  6/1/2017 0:03             0              Bx39   \n",
       "\n",
       "                      OriginName  OriginLat  OriginLong  \\\n",
       "0                     4 AV/95 ST  40.616104  -74.031143   \n",
       "6   GERRITSEN AV/GERRITSEN BEACH  40.587101  -73.918503   \n",
       "11                    87 ST/4 Av  40.621925  -74.028496   \n",
       "12        WYCKOFF ST/PALMETTO ST  40.699150  -73.910477   \n",
       "13      SOUNDVIEW AV/STEPHENS AV  40.807869  -73.852715   \n",
       "\n",
       "                      DestinationName  DestinationLat  DestinationLong  \\\n",
       "0             BROWNSVILLE ROCKAWAY AV       40.656048       -73.907379   \n",
       "6               MIDWOOD KINGS HWY STA       40.608433       -73.957100   \n",
       "11       MANHATTAN BEACH KINGSBORO CC       40.578094       -73.940170   \n",
       "12  DNTWN BKLYN TILLARY ST via HALSEY       40.693939       -73.990311   \n",
       "13  WAKEFIELD 241 ST via WHITE PLS RD       40.903309       -73.849922   \n",
       "\n",
       "   VehicleRef    ...      ScheduledArrivalTime  Unnamed: 17 expected_date  \\\n",
       "0    NYCT_430    ...                  00:06:14          NaN      6/1/2017   \n",
       "6   NYCT_4611    ...                  00:08:00          NaN      6/1/2017   \n",
       "11  NYCT_7141    ...                  00:05:55          NaN      6/1/2017   \n",
       "12  NYCT_6503    ...                  00:05:55          NaN      6/1/2017   \n",
       "13  NYCT_4723    ...                  00:04:12          NaN      6/1/2017   \n",
       "\n",
       "    Scheduled_datetime   Expected_datetime             delay  \\\n",
       "0  2017-06-01 00:06:14 2017-06-01 00:03:00 -1 days +23:56:46   \n",
       "6  2017-06-01 00:08:00 2017-06-01 00:03:00 -1 days +23:55:00   \n",
       "11 2017-06-01 00:05:55 2017-06-01 00:03:00 -1 days +23:57:05   \n",
       "12 2017-06-01 00:05:55 2017-06-01 00:03:00 -1 days +23:57:05   \n",
       "13 2017-06-01 00:04:12 2017-06-01 00:04:00 -1 days +23:59:48   \n",
       "\n",
       "   Scheduled_HourOfDay delay_second delay_minute delay_days  \n",
       "0                    0        86206  1436.766667         -1  \n",
       "6                    0        86100  1435.000000         -1  \n",
       "11                   0        86225  1437.083333         -1  \n",
       "12                   0        86225  1437.083333         -1  \n",
       "13                   0        86388  1439.800000         -1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#calculating the time difference for those buses that arrived before time\n",
    "df_neg1['neg1_minute_diff'] = df_neg1['Expected_datetime'].dt.minute - df_neg1['Scheduled_datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1     70133\n",
      " 0     64714\n",
      "-2     48293\n",
      "-3     28850\n",
      "-4     15888\n",
      "-5      9125\n",
      "-6      5552\n",
      "-7      3716\n",
      "-8      2547\n",
      "-9      1955\n",
      " 58     1789\n",
      "-10     1599\n",
      " 57     1587\n",
      " 59     1478\n",
      " 56     1330\n",
      "-11     1191\n",
      "-12      944\n",
      " 55      939\n",
      "-13      712\n",
      " 54      704\n",
      "-14      582\n",
      "-15      532\n",
      " 53      505\n",
      "-16      400\n",
      " 52      357\n",
      " 51      355\n",
      " 50      323\n",
      " 49      292\n",
      "-18      284\n",
      "-17      282\n",
      "       ...  \n",
      " 23        8\n",
      " 13        8\n",
      " 10        7\n",
      " 11        7\n",
      " 16        7\n",
      " 2         6\n",
      "-41        6\n",
      " 9         5\n",
      " 6         5\n",
      " 1         5\n",
      "-40        5\n",
      "-50        5\n",
      " 8         4\n",
      "-44        4\n",
      "-42        4\n",
      "-51        3\n",
      "-47        2\n",
      "-46        2\n",
      "-45        2\n",
      " 3         2\n",
      " 7         2\n",
      "-43        2\n",
      "-55        2\n",
      "-48        2\n",
      "-58        1\n",
      "-52        1\n",
      "-49        1\n",
      " 4         1\n",
      "-54        1\n",
      "-57        1\n",
      "Name: neg1_minute_diff, Length: 115, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#creating a new feature \"neg1_minute_diff\" to account for the minute differences.\n",
    "print(df_neg1.neg1_minute_diff.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajee\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#fixing the values of 'delay_minute' column\n",
    "df_neg1.loc[(df_neg1['neg1_minute_diff'] < -5) & (df_neg1['neg1_minute_diff'] > 5), 'delay_minute'] = 6\n",
    "\n",
    "df_neg1.loc[(df_neg1['neg1_minute_diff'] > 0) & (df_neg1['neg1_minute_diff'] < 5), 'delay_minute'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordedAtTime</th>\n",
       "      <th>DirectionRef</th>\n",
       "      <th>PublishedLineName</th>\n",
       "      <th>OriginName</th>\n",
       "      <th>OriginLat</th>\n",
       "      <th>OriginLong</th>\n",
       "      <th>DestinationName</th>\n",
       "      <th>DestinationLat</th>\n",
       "      <th>DestinationLong</th>\n",
       "      <th>VehicleRef</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>expected_date</th>\n",
       "      <th>Scheduled_datetime</th>\n",
       "      <th>Expected_datetime</th>\n",
       "      <th>delay</th>\n",
       "      <th>Scheduled_HourOfDay</th>\n",
       "      <th>delay_second</th>\n",
       "      <th>delay_minute</th>\n",
       "      <th>delay_days</th>\n",
       "      <th>neg1_minute_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>B8</td>\n",
       "      <td>4 AV/95 ST</td>\n",
       "      <td>40.616104</td>\n",
       "      <td>-74.031143</td>\n",
       "      <td>BROWNSVILLE ROCKAWAY AV</td>\n",
       "      <td>40.656048</td>\n",
       "      <td>-73.907379</td>\n",
       "      <td>NYCT_430</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:06:14</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>-1 days +23:56:46</td>\n",
       "      <td>0</td>\n",
       "      <td>86206</td>\n",
       "      <td>1436.766667</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>B31</td>\n",
       "      <td>GERRITSEN AV/GERRITSEN BEACH</td>\n",
       "      <td>40.587101</td>\n",
       "      <td>-73.918503</td>\n",
       "      <td>MIDWOOD KINGS HWY STA</td>\n",
       "      <td>40.608433</td>\n",
       "      <td>-73.957100</td>\n",
       "      <td>NYCT_4611</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:08:00</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>-1 days +23:55:00</td>\n",
       "      <td>0</td>\n",
       "      <td>86100</td>\n",
       "      <td>1435.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>87 ST/4 Av</td>\n",
       "      <td>40.621925</td>\n",
       "      <td>-74.028496</td>\n",
       "      <td>MANHATTAN BEACH KINGSBORO CC</td>\n",
       "      <td>40.578094</td>\n",
       "      <td>-73.940170</td>\n",
       "      <td>NYCT_7141</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:05:55</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>-1 days +23:57:05</td>\n",
       "      <td>0</td>\n",
       "      <td>86225</td>\n",
       "      <td>1437.083333</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>1</td>\n",
       "      <td>B26</td>\n",
       "      <td>WYCKOFF ST/PALMETTO ST</td>\n",
       "      <td>40.699150</td>\n",
       "      <td>-73.910477</td>\n",
       "      <td>DNTWN BKLYN TILLARY ST via HALSEY</td>\n",
       "      <td>40.693939</td>\n",
       "      <td>-73.990311</td>\n",
       "      <td>NYCT_6503</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:05:55</td>\n",
       "      <td>2017-06-01 00:03:00</td>\n",
       "      <td>-1 days +23:57:05</td>\n",
       "      <td>0</td>\n",
       "      <td>86225</td>\n",
       "      <td>1437.083333</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6/1/2017 0:03</td>\n",
       "      <td>0</td>\n",
       "      <td>Bx39</td>\n",
       "      <td>SOUNDVIEW AV/STEPHENS AV</td>\n",
       "      <td>40.807869</td>\n",
       "      <td>-73.852715</td>\n",
       "      <td>WAKEFIELD 241 ST via WHITE PLS RD</td>\n",
       "      <td>40.903309</td>\n",
       "      <td>-73.849922</td>\n",
       "      <td>NYCT_4723</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/1/2017</td>\n",
       "      <td>2017-06-01 00:04:12</td>\n",
       "      <td>2017-06-01 00:04:00</td>\n",
       "      <td>-1 days +23:59:48</td>\n",
       "      <td>0</td>\n",
       "      <td>86388</td>\n",
       "      <td>1439.800000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordedAtTime  DirectionRef PublishedLineName  \\\n",
       "0   6/1/2017 0:03             0                B8   \n",
       "6   6/1/2017 0:03             0               B31   \n",
       "11  6/1/2017 0:03             1                B1   \n",
       "12  6/1/2017 0:03             1               B26   \n",
       "13  6/1/2017 0:03             0              Bx39   \n",
       "\n",
       "                      OriginName  OriginLat  OriginLong  \\\n",
       "0                     4 AV/95 ST  40.616104  -74.031143   \n",
       "6   GERRITSEN AV/GERRITSEN BEACH  40.587101  -73.918503   \n",
       "11                    87 ST/4 Av  40.621925  -74.028496   \n",
       "12        WYCKOFF ST/PALMETTO ST  40.699150  -73.910477   \n",
       "13      SOUNDVIEW AV/STEPHENS AV  40.807869  -73.852715   \n",
       "\n",
       "                      DestinationName  DestinationLat  DestinationLong  \\\n",
       "0             BROWNSVILLE ROCKAWAY AV       40.656048       -73.907379   \n",
       "6               MIDWOOD KINGS HWY STA       40.608433       -73.957100   \n",
       "11       MANHATTAN BEACH KINGSBORO CC       40.578094       -73.940170   \n",
       "12  DNTWN BKLYN TILLARY ST via HALSEY       40.693939       -73.990311   \n",
       "13  WAKEFIELD 241 ST via WHITE PLS RD       40.903309       -73.849922   \n",
       "\n",
       "   VehicleRef       ...         Unnamed: 17  expected_date  \\\n",
       "0    NYCT_430       ...                 NaN       6/1/2017   \n",
       "6   NYCT_4611       ...                 NaN       6/1/2017   \n",
       "11  NYCT_7141       ...                 NaN       6/1/2017   \n",
       "12  NYCT_6503       ...                 NaN       6/1/2017   \n",
       "13  NYCT_4723       ...                 NaN       6/1/2017   \n",
       "\n",
       "    Scheduled_datetime   Expected_datetime             delay  \\\n",
       "0  2017-06-01 00:06:14 2017-06-01 00:03:00 -1 days +23:56:46   \n",
       "6  2017-06-01 00:08:00 2017-06-01 00:03:00 -1 days +23:55:00   \n",
       "11 2017-06-01 00:05:55 2017-06-01 00:03:00 -1 days +23:57:05   \n",
       "12 2017-06-01 00:05:55 2017-06-01 00:03:00 -1 days +23:57:05   \n",
       "13 2017-06-01 00:04:12 2017-06-01 00:04:00 -1 days +23:59:48   \n",
       "\n",
       "   Scheduled_HourOfDay delay_second delay_minute delay_days neg1_minute_diff  \n",
       "0                    0        86206  1436.766667         -1               -3  \n",
       "6                    0        86100  1435.000000         -1               -5  \n",
       "11                   0        86225  1437.083333         -1               -2  \n",
       "12                   0        86225  1437.083333         -1               -2  \n",
       "13                   0        86388  1439.800000         -1                0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the 'neg1_minute_diff' column from df_neg1\n",
    "df_neg1 = df_neg1.drop('neg1_minute_diff', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining df_zer0 and df_neg1 into one dataframe\n",
    "df = pd.concat([df_zero, df_neg1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.delay_days.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating output variable\n",
    "df['on_time'] = np.where((df['delay_minute'] > 5) | (df['delay_minute'] < -1), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting value count for binary output variable\n",
    "df['on_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['delay_days'] < 0, 'delay_minute'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examining delay days\n",
    "df['delay_days'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_1 = df[df['delay_days'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_1.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_1.Scheduled_HourOfDay.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_1.on_time.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filtered dataframe df_day_1, above, represents those instances when the bus was delayed.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering dataframe for delay_days equal to -1, the buses that arrived before time.\n",
    "df_day_neg1 = df[df['delay_days'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_neg1.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_neg1.Scheduled_datetime.dt.date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_neg1.Expected_datetime.dt.date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_neg1['neg1_minute_diff'] = df_day_neg1['Expected_datetime'].dt.minute - df_day_neg1['Scheduled_datetime'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_day_neg1.neg1_minute_diff.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_neg1.Scheduled_HourOfDay.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_neg1.on_time.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_0.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_0.Scheduled_HourOfDay.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_0.Expected_datetime.dt.date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe by filtering the dataset for values of 'delay_neg'\n",
    "df_neg = df[df['delay_neg']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['delay_neg']<0] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting 'delay' column from timedelta to datetime\n",
    "df['delay'] = pd.to_datetime(df['delay'], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the minutes from 'delay' column\n",
    "df['delay_minute'] = df['delay'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking datatype of 'delay_minute' column\n",
    "df['delay_minute'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating output variable\n",
    "df['on_time'] = np.where((df['delay_minute'] > 5) | (df['delay_minute'] < -1), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"source\"] = [(i, j) for i, j in zip(df[\"OriginLat\"], df[\"OriginLong\"])]\n",
    "\n",
    "df[\"destination\"] = [(i, j) for i, j in zip(df[\"DestinationLat\"], df[\"DestinationLong\"])]\n",
    "\n",
    "df[\"dist\"] = [geopy.distance.distance(i, j).km for i, j in zip(df[\"source\"], df[\"destination\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Vehicle_location2'] = [(i,j) for i, j in zip(df['VehicleLocation.Latitude'], df['VehicleLocation.Longitude'])]\n",
    "df[\"VehicleToDestination\"] = [geopy.distance.distance(i, j).km for i, j in zip(df[\"Vehicle_location2\"], df[\"destination\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(timeout=3)\n",
    "df['address_origin'] = [geolocator.reverse(i,j) for i, j in df['source']]\n",
    "\n",
    "#df['location_address_origin'] = df['source'].apply(geolocator.reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.PublishedLineName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the 'on time' column and value counts to check how many buses were on time\n",
    "df['on_time'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of a total of 1,048,575 recorded instances, 274,056 buses arrived on time and 774,519 buses were delayed.  This shows a significant class imbalance in our target variable that I will address before building a machine learning model from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling our data to correct for imbalance in the class variable 'on_time'\n",
    "\n",
    "# Class count, 2 represents benign, and 4 represents malignant\n",
    "count_ontime_0, count_ontime_1 = df.on_time.value_counts()\n",
    "print(count_ontime_0)\n",
    "print(count_ontime_1)\n",
    "# Divide by class\n",
    "df_ontime_0 = df[df['on_time'] == 0]\n",
    "df_ontime_1 = df[df['on_time'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the observations with class zero, equal to the number of obervations equal\n",
    "df_ontime_0_under = df_ontime_0.sample(count_ontime_1)\n",
    "\n",
    "#create a new dataframe with the same number of values for our two classes\n",
    "new_df = pd.concat([df_ontime_0_under, df_ontime_1], axis=0)\n",
    "new_df = new_df.reset_index()\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(new_df.on_time.value_counts())\n",
    "\n",
    "new_df.on_time.value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking a quick glimpse of new_df\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the 'OriginName' column\n",
    "new_df.OriginName.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to know exactly how many different origin points we have in our data; by subsetting the \"OriginName\" column, we see that there are 457 unique origin points.  Next I will subset the data based on the two different values of the output variable, \"on_time\", to see if there is any relation between the Origin point of the bus and whether its on time or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before performing any additional pre processing or feature creation, I will create a machine learing model with a decision tree to get an idea of the accuracy of the model at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating two subsets of the dataframe; new_df_0 represents the subset with buses not on time, and new_df_1\n",
    "# represents the subset with buses on time.\n",
    "new_df_0 = new_df[new_df['on_time'] == 0]\n",
    "new_df_1 = new_df[new_df['on_time'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the PublishedLineName column\n",
    "print(new_df_0.PublishedLineName.describe())\n",
    "print(new_df_1.PublishedLineName.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the DestinationName column\n",
    "print(new_df_0.DestinationName.describe())\n",
    "print()\n",
    "print(new_df_1.DestinationName.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the 'OriginName' column for those buses that did not make it to their destinations on time.\n",
    "new_df_0.OriginName.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the 'OriginName' column for those buses that made it on time.\n",
    "new_df_1.OriginName.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'm assuming the column \"OriginName\" to represent a bus stop, defined by the street intersection at which that bus stop is located at, from where each bus's route started, for each recorded observation in the data.\n",
    "\n",
    "After subsetting the dataframe based on the binary values of the output variable, 'on_time', I noticed that the two subsets of the dataframe had similar number of unique \"OriginNames; 448 out of 459 for the subset representing buses that were delayed and 446 out of 459 for the subset of data representing buses that were on time.  This suggests that both of the separate subsets had observations from almost all of the same bus stops, and that no one particular route was either always on time or always delayed.  Further analysis of the \"OriginName\" column below may help us see a pattern between the starting point (OriginName) of a bus's route and whether that bus was on time or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examing the top ten value_counts of dataframe new_df_0.\n",
    "new_df_1.OriginName.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examining the top ten value_counts of dataframe new_df_0\n",
    "new_df_0.OriginName.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examining the two lists of \"OriginName\" value counts above, I noticed that the two lists from the separate subsets of the data share alot of the same bus stop names.  Bus stops (OriginName) such as E 126 ST/2 AV, ELTINGVILLE/TRANSIT CENTER, MERRICK BL/ARCHER AV, FLATBUSH AV/KINGS PLAZA, HARWAY AV/BAY 37 ST, and TEARDROP/LAYOVER were involved with alot of delays but also alot of buses that made it to their destination on time.  Considering that this data is regarding New York City, this may suggest that their is another underlying factor causing delays, such as high traffic on the roads due to seasonality or caused by special events at or near some of the specific bus stops that I mentioned here. \n",
    "\n",
    "Aside from this, it should be noted that of the 20 Origin names in the second list of value counts (which represents those OriginNames that were related to those buses being delayed) 11 are unique; that is they are not in the top 20 list of value counts for origin names that were related to those buses that were on time.  Names such as W FARMS RD/WESTCHESTER AV, BROADWAY/ISHAM ST, ASTOR PL/3 AV, AND 41 RD/MAIN ST, just to name a few.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making two scatter plots to show the origin locations of buses on time, and not on time, using origin latitude and origin\n",
    "#longitude\n",
    "\n",
    "#setting figure size\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "#making a plot figure that will have one row with two plots in each row\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(x=new_df_0.OriginLat, y=new_df_0.OriginLong, color='blue')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Origin Locations for buses Not On Time')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(x=new_df_1.OriginLat, y=new_df_1.OriginLong, color='blue')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Origin Locations for buses On Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making two scatter plots to show the origin locations of buses on time, and not on time, using origin latitude and origin\n",
    "#longitude\n",
    "\n",
    "#setting figure size\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "#making a plot figure that will have one row with two plots in each row\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(x=new_df_0.DestinationLat, y=new_df_0.DestinationLong, color='blue')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Destination Locations for buses Not On Time')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(x=new_df_1.DestinationLat, y=new_df_1.DestinationLong, color='blue')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Destination Locations for buses On Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two sets of scatterplot show the origin locations and destination locations using latitude and longitude for all buses, on time and those not on time, from the dataset.  As you can see, they are near identical for both scenarios, which further states that the bus route in of itself was not the sole factor for causing a bus to be on time to its destination or delayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_0.DirectionRef.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_1.DirectionRef.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dist'] = df['dist'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dist'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking dataframe to see which rows have non numeric data. False means its not int or float\n",
    "#new_df.applymap(lambda x: isinstance(x, (int, float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting 'DistanceFromStop' to numeric, and coercing errors which will make errors to nan, which i will correct below\n",
    "#new_df['DistanceFromStop'] = pd.to_numeric(new_df['DistanceFromStop'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the total number of null items in \"DistanceFromStop\"\n",
    "#new_df['DistanceFromStop'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rechecking the dtype of 'DistanceFromStop'\n",
    "#new_df['DistanceFromStop'].dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the column shape\n",
    "#new_df['DistanceFromStop'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this just gave me a long pandas series\n",
    "#print(np.isnan(new_df['DistanceFromStop']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one way to check which rows have the nan or null values in \"DistanceFromStop\" column, by subsetting database for null values\n",
    "#print(new_df[pd.to_numeric(new_df['DistanceFromStop'], errors='coerce').isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the Nan values.  I could have also replaced the NaN values with with fillna(0)\n",
    "#new_df = new_df.drop(new_df.index[[53965,56430,61000,65636]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rechecking the shape of the 'DistanceFromStop' column\n",
    "#new_df['DistanceFromStop'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping some columns and splitting the data and creating the initial train and test splits.\n",
    "X = new_df.drop(['index', 'RecordedAtTime', 'ArrivalProximityText', 'Unnamed: 17', 'PublishedLineName', 'VehicleRef', \n",
    "                 'NextStopPointName', 'ExpectedArrivalTime', 'ScheduledArrivalTime',\n",
    "                 'expected_arrival', 'scheduled_arrival', 'delay', 'delay_minute', 'on_time', 'OriginName',\n",
    "                 'DestinationName','source', 'destination', 'Vehicle_location2', 'DistanceFromStop'], 1)\n",
    "\n",
    "#getting dummy values for categorical data, and creating dataframe of the independent (predictor) values\n",
    "#XD_df = pd.get_dummies(X, columns=['OriginName', 'DestinationName'])\n",
    "\n",
    "\n",
    "Y = new_df['on_time']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking type\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking which column has NaN value\n",
    "X.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for location of NaN values in \"DistanceFromStop\" column\n",
    "#print(XD_df[pd.to_numeric(XD_df['DistanceFromStop'], errors='coerce').isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the Nan values.  I could have also replaced the NaN values with with fillna(0)\n",
    "#XD_df = XD_df.drop(XD_df.index[4606])\n",
    "#Y = Y.drop(Y.index[4606])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=.3, random_state=20)\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)\n",
    "\n",
    "#checking for any NaN values in our data.\n",
    "#print(np.isnan(train_Y).any())\n",
    "#print(np.isnan(train_X).any().sum())\n",
    "#print(np.isnan(test_Y).any())\n",
    "#print(np.isnan(test_X).any().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform grid search to find the optimal parameters for our decision tree model\n",
    "dtree = tree.DecisionTreeClassifier(random_state=2)\n",
    "tree_param_grid = {'max_depth':[4,6,10], 'min_samples_split':[6,8,10,15], 'max_features':[2,4,6,8], \n",
    "                   'criterion':['gini', 'entropy']}\n",
    "dtree_grid = GridSearchCV(dtree, tree_param_grid, cv=5, verbose=3)\n",
    "dtree_grid.fit(train_X, train_Y)\n",
    "print('Best parameters for decision tree:', dtree_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters for decision tree:', dtree_grid.best_params_)\n",
    "print('Best score for decision tree: ', dtree_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the first model by Initializing and training our tree before any additional preprocessing\n",
    "decision_tree = tree.DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    max_features=4,\n",
    "    max_depth=10,\n",
    "    min_samples_split=8,\n",
    "    random_state = 201\n",
    ")\n",
    "\n",
    "#set start time\n",
    "start_time_tree = datetime.datetime.now()\n",
    "\n",
    "#train our tree\n",
    "decision_tree.fit(train_X, train_Y)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred_dtree = decision_tree.predict(test_X)\n",
    "\n",
    "#get accuracy score from our model\n",
    "print('Accuracy score for decision tree Model: ' + str(metrics.accuracy_score(test_Y, y_pred_dtree)))\n",
    "\n",
    "#calculate end time\n",
    "end_time_tree = datetime.datetime.now()\n",
    "\n",
    "#print the execution run time for our model\n",
    "print('\\nDuration: {}'.format(end_time_tree - start_time_tree))\n",
    "print()\n",
    "\n",
    "#get accuracy score of decision tree\n",
    "tree_score = cross_val_score(decision_tree, X, Y, cv=10, scoring='accuracy')\n",
    "print(tree_score)\n",
    "print('Average cross validated score from our decision tree model is: ' + str(np.mean(tree_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest = SelectKBest(f_classif)\n",
    "pipeline = Pipeline([('kbest', kbest), ('lr', LogisticRegression())])\n",
    "gridcv_k_log = GridSearchCV(pipeline, {'kbest__k': [1,2,3,4], 'lr__C': np.logspace(-10, 10, 5)}, verbose=3)\n",
    "gridcv_k_log.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters for k_log:', gridcv_k_log.best_params_)\n",
    "print('Best score for k_log: ', gridcv_k_log.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize and train our model\n",
    "LogReg = LogisticRegression(C=1e9, random_state=12)\n",
    "\n",
    "#set start time\n",
    "start_time4 = datetime.datetime.now()\n",
    "\n",
    "#fit and train the model\n",
    "LogReg.fit(train_X, train_Y)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred_LogReg = LogReg.predict(test_X)\n",
    "\n",
    "#get accuracy score from our model\n",
    "print('Accuracy score for Logistic regression Model: ' + str(metrics.accuracy_score(test_Y, y_pred_LogReg)))\n",
    "\n",
    "#calculate end time\n",
    "end_time4 = datetime.datetime.now()\n",
    "\n",
    "#print the execution run time for our model\n",
    "print('\\nDuration: {}'.format(end_time4 - start_time4))\n",
    "print()\n",
    "\n",
    "#get average accuracy score using cross validation\n",
    "LogReg_cvs = cross_val_score(LogReg, X, Y, cv=10, scoring='accuracy')\n",
    "print(LogReg_cvs)\n",
    "\n",
    "print('Average cross validated score from our log regression model is: ' + str(np.mean(LogReg_cvs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data so that all variables have a mean of 0 and standard deviation\n",
    "# o\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply PCA\n",
    "\n",
    "pca = PCA(.95)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "comp_no = pca.n_components_\n",
    "comp_var_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "print(comp_no)\n",
    "print(comp_var_ratio)\n",
    "#print(p_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca data to dataframe\n",
    "pca_df = pd.DataFrame(data=X_pca)\n",
    "print(pca_df.head())\n",
    "print(pca_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After applying PCA, I split the data into a second set of train and test groups\n",
    "\n",
    "train_X_pca, test_X_pca, train_Y_pca, test_Y_pca = train_test_split(X_pca, Y, test_size=.3, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform grid search to find the optimal parameters for our random forest model, after applying PCA\n",
    "rforest = ensemble.RandomForestClassifier(random_state=20)\n",
    "forest_param_grid = {'n_estimators':[50,100], 'max_depth':[4,6,8,10], 'min_samples_split':[6,8,10,12], \n",
    "                     'max_features':[2,4,6], 'criterion':['entropy', 'gini']}\n",
    "rforest_grid = GridSearchCV(rforest, forest_param_grid, cv=10, verbose=3)\n",
    "rforest_grid.fit(train_X, train_Y)\n",
    "print('Best parameters for decision tree:', rforest_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best score for Random Forest:', rforest_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize and train our random forest model with PCA\n",
    "rand_forest_pca = ensemble.RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=10, max_features=6,\n",
    "                                              min_samples_split=10, random_state=300)\n",
    "\n",
    "#set start time\n",
    "start_time_rforest = datetime.datetime.now()\n",
    "\n",
    "rand_forest_pca.fit(train_X_pca, train_Y_pca)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred_rforest_pca = rand_forest_pca.predict(test_X_pca)\n",
    "\n",
    "#get accuracy score from our model\n",
    "print('Accuracy score for Random Forest Model: ' + str(metrics.accuracy_score(test_Y_pca, y_pred_rforest)))\n",
    "\n",
    "#calculate end time\n",
    "end_time_rforest = datetime.datetime.now()\n",
    "\n",
    "#print the execution run time for our model\n",
    "print('\\nDuration: {}'.format(end_time_rforest - start_time_rforest))\n",
    "print()\n",
    "\n",
    "#get average accuracy score of our random forest through cross validation\n",
    "rforest_pca_cvs = cross_val_score(rand_forest_pca, X_pca, Y, cv=10, scoring='accuracy')\n",
    "print(rforest_pca_cvs)\n",
    "print('Average cross validated score from our Random Forest Model is: ' + str(np.mean(rforest_pca_cvs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create confusion matrix for random forest and PCA\n",
    "confusion_matrix(test_Y_pca, y_pred_rforest_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get AUC and create ROC\n",
    "# predict probabilities\n",
    "probs_rforest_pca = LogReg.predict_proba(test_X_pca)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs_rforest_pca = probs_rforest_pca[:, 1]\n",
    "# calculate AUC\n",
    "rforest_auc = roc_auc_score(test_Y_pca, probs_rforest_pca)\n",
    "print('AUC Score: %.3f' % rforest_auc)\n",
    "# calculate roc curve\n",
    "fpr_rforest_pca, tpr_rforest_pca, thresholds_rforest_pca = roc_curve(test_Y_pca, probs_rforest_pca)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr_rforest_pca, tpr_rforest_pca, marker='.')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform classification report of the logistic regression model\n",
    "class_names = ['Class_0', 'Class_1']\n",
    "rforest_report = classification_report(test_Y_pca, y_pred_rforest_pca, target_names=class_names)\n",
    "print(rforest_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run gridsearchcv to find the best parameters for gradient boosting using PCA\n",
    "gboost_param_grid = {'n_estimators':[200,400,600], 'max_depth':[2,4,6], 'min_samples_leaf': [3, 5, 9], \n",
    "                     'learning_rate': [.05, .02, .01], 'subsample': [.7, .8, .9]}\n",
    "gb_model = ensemble.GradientBoostingClassifier(random_state=67)\n",
    "\n",
    "gb_grid = GridSearchCV(gb_model, gboost_param_grid, cv=5)\n",
    "gb_grid.fit(train_X_pca, train_Y_pca)\n",
    "print('Best parameters for Gradient Boost Model are:', gb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters for Gradient Boost Model are:', gb_grid.best_params_)\n",
    "print('Best score for Gradient Boost Model are:', gb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the model using PCA\n",
    "Grad_boost_pca = ensemble.GradientBoostingClassifier(learning_rate=0.02, max_depth=2, min_samples_leaf=5, \n",
    "                                                 n_estimators=200, subsample=0.7, random_state=67)\n",
    "\n",
    "#set start time\n",
    "start_time_gb = datetime.datetime.now()\n",
    "\n",
    "#fit and train the model\n",
    "Grad_boost_pca.fit(train_X_pca, train_Y_pca)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred_Gboost_pca = Grad_boost.predict(test_X_pca)\n",
    "\n",
    "#get accuracy score from our model\n",
    "print('Accuracy score for Gradient Boost Model: ' + str(metrics.accuracy_score(test_Y_pca, y_pred_Gboost_pca)))\n",
    "\n",
    "#calculate end time\n",
    "end_time_gb = datetime.datetime.now()\n",
    "\n",
    "#print the execution run time for our model\n",
    "print('\\nDuration: {}'.format(end_time_gb - start_time_gb))\n",
    "print()\n",
    "\n",
    "#get average accuracy score using cross validation\n",
    "Grad_boost_cvs_pca = cross_val_score(Grad_boost_pca, X_pca, Y, cv=5, scoring='accuracy')\n",
    "print(Grad_boost_cvs_pca)\n",
    "\n",
    "print('Average cross validated score from our Gradient Boosting model is: ' + str(np.mean(Grad_boost_cvs_pca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get AUC and create ROC\n",
    "# predict probabilities\n",
    "probs_Gboost_pca = Grad_boost_pca.predict_proba(test_X_pca)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs_Gboost_pca = probs_Gboost_pca[:, 1]\n",
    "# calculate AUC\n",
    "Gboost_auc = roc_auc_score(test_Y_pca, probs_Gboost_pca)\n",
    "print('AUC Score: %.3f' % Gboost_auc)\n",
    "# calculate roc curve\n",
    "fpr_Gboost_pca, tpr_Gboost_pca, thresholds_Gboost_pca = roc_curve(test_Y_pca, probs_Gboost_pca)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr_Gboost_pca, tpr_Gboost_pca, marker='.')\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "# perform classification report of the Gradient Boosting model\n",
    "class_names = ['Class_0', 'Class_1']\n",
    "Gboost_report = classification_report(test_Y_pca, y_pred_Gboost_pca, target_names=class_names)\n",
    "print(Gboost_report)\n",
    "print()\n",
    "#confusion matrix\n",
    "print('Confusion Matrix:')\n",
    "confusion_matrix(test_Y_pca, y_pred_Gboost_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize and train our model after PCA\n",
    "LogReg_pca = LogisticRegression(C=1e9, random_state=12)\n",
    "\n",
    "#set start time\n",
    "start_time4 = datetime.datetime.now()\n",
    "\n",
    "#fit and train the model\n",
    "LogReg_pca.fit(train_X_pca, train_Y_pca)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred_LogReg_pca = LogReg_pca.predict(test_X_pca)\n",
    "\n",
    "#get accuracy score from our model\n",
    "print('Accuracy score for Logistic regression Model after pca: ' + str(metrics.accuracy_score(test_Y_pca, y_pred_LogReg_pca)))\n",
    "\n",
    "#calculate end time\n",
    "end_time4 = datetime.datetime.now()\n",
    "\n",
    "#print the execution run time for our model\n",
    "print('\\nDuration: {}'.format(end_time4 - start_time4))\n",
    "print()\n",
    "\n",
    "#get average accuracy score using cross validation\n",
    "LogReg_cvs_pca = cross_val_score(LogReg_pca, X_pca, Y, cv=10, scoring='accuracy')\n",
    "print(LogReg_cvs_pca)\n",
    "\n",
    "print('Average cross validated score from our log regression model is: ' + str(np.mean(LogReg_cvs_pca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get AUC and create ROC\n",
    "# predict probabilities\n",
    "probs_LogReg_pca = LogReg_pca.predict_proba(test_X)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs_LogReg_pca = probs_LogReg_pca[:, 1]\n",
    "# calculate AUC\n",
    "LogReg_pca_auc = roc_auc_score(test_Y_pca, probs_LogReg_pca)\n",
    "print('AUC Score: %.3f' % LogReg_pca_auc)\n",
    "# calculate roc curve\n",
    "fpr_LogReg_pca, tpr_LogReg_pca, thresholds_LogReg_pca = roc_curve(test_Y_pca, probs_LogReg_pca)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr_LogReg_pca, tpr_LogReg_pca, marker='.')\n",
    "# show the plot\n",
    "plt.show()\n",
    "print()\n",
    "\n",
    "# perform classification report of the logistic regression model\n",
    "class_names = ['Class_0', 'Class_1']\n",
    "LogReg_report_pca = classification_report(test_Y_pca, y_pred_LogReg_pca, target_names=class_names)\n",
    "print(LogReg_report_pca)\n",
    "print()\n",
    "\n",
    "# create confusion matrix\n",
    "confusion_matrix(test_Y_pca, y_pred_LogReg_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform grid search to find the optimal parameters for our KNN model using full data.\n",
    "KNN_model = KNeighborsClassifier()\n",
    "KNN_params = {'n_neighbors':[5,10,15], 'weights':['uniform', 'distance']}\n",
    "KNN_grid = GridSearchCV(KNN_model, KNN_params, cv=5)\n",
    "KNN_grid.fit(train_X_pca, train_Y_pca)\n",
    "print('Best parameters for data:', KNN_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize and train our model using the training set\n",
    "KNN_pca = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "\n",
    "#set start time\n",
    "starttime_knn = datetime.datetime.now()\n",
    "\n",
    "#fit and train the model\n",
    "KNN_pca.fit(train_X_pca,train_Y_pca)\n",
    "\n",
    "#Make predictions using test_X, and store results in new variable\n",
    "y_pred_KNN_pca = KNN_pca.predict(test_X_pca)\n",
    "\n",
    "print('Accuracy score for KNN Model: ' + str(metrics.accuracy_score(test_Y_pca, y_pred_KNN_pca)))\n",
    "\n",
    "#calculate end time\n",
    "endtime_knn = datetime.datetime.now()\n",
    "\n",
    "#print the execution run time for our model\n",
    "print('\\nDuration: {}'.format(endtime_knn - starttime_knn))\n",
    "print()\n",
    "\n",
    "\n",
    "KNN_cvs_pca = cross_val_score(KNN_pca, X_pca, Y, cv=5, scoring='accuracy')\n",
    "print(KNN_cvs_pca)\n",
    "print('Average cross validated score from our KNN model is: ' + str(np.mean(KNN_cvs_pca)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get AUC and create ROC\n",
    "# predict probabilities\n",
    "probs_KNN_pca = KNN_pca.predict_proba(test_X_pca)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs_KNN_pca = probs_KNN_pca[:, 1]\n",
    "# calculate AUC\n",
    "KNN_pca_auc = roc_auc_score(test_Y_pca, probs_KNN_pca)\n",
    "print('AUC Score: %.3f' % KNN_pca_auc)\n",
    "# calculate roc curve\n",
    "fpr_KNN_pca, tpr_KNN_pca, thresholds_KNN_pca = roc_curve(test_Y_pca, probs_KNN_pca)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr_KNN_pca, tpr_KNN_pca, marker='.')\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "# perform classification report of the KNN model\n",
    "class_names = ['Class_0', 'Class_1']\n",
    "KNN_report_pca = classification_report(test_Y_pca, y_pred_KNN_pca, target_names=class_names)\n",
    "print(KNN_report_pca)\n",
    "\n",
    "# confusion Matrix\n",
    "confusion_matrix(test_Y_pca, y_pred_KNN_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest = SelectKBest(f_classif)\n",
    "pipeline = Pipeline([('kbest', kbest), ('lr', LogisticRegression())])\n",
    "grid_search = GridSearchCV(pipeline, {'kbest__k': [1,2,3,4], 'lr__C': np.logspace(-10, 10, 5)})\n",
    "grid_search.fit(train_X_pca, train_Y_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing GridsearchCV to get the best parameters for SelectKBest.\n",
    "#Kbest = SelectKBest().fit_transform(X, Y)\n",
    "#K_params = {'k':[1,2,3,4,5,6], 'score_func':[chi2, f_classif]}\n",
    "#Kgrid = GridSearchCV(Kbest, K_params, cv=5, scoring='accuracy')\n",
    "#Kgrid.fit(X, Y)\n",
    "#print('Best parameters for SelectKBest:', Kgrid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying selectKBest.\n",
    "X_skb = SelectKBest(f_classif, k=6).fit_transform(X, Y)\n",
    "print(X_skb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After applying SelectKBest, I split the data into a third set of train and test groups\n",
    "train_X_skb, test_X_skb, train_Y_skb, test_Y_skb = train_test_split(X_skb, Y, test_size=.3, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#an unconventional way to check for the null, nan, or NaT value in scheduled_arrival\n",
    "#df['checkNaN'] = df['scheduled_arrival'].isnull()\n",
    "#print(np.where(df['checkNaN'] == True)) \n",
    "\n",
    "#plt.figure(figsize=(10,10))\n",
    "#sns.jointplot(x=new_df_0.OriginLat, y=new_df_0.OriginLong, size=10)\n",
    "#plt.ylabel('Longitude', fontsize=12)\n",
    "#plt.xlabel('Latitude', fontsize=12)\n",
    "#plt.show()\n",
    "#sns.despine\n",
    "\n",
    "#plt.figure(figsize=(10,10))\n",
    "#sns.jointplot(x=new_df_1.OriginLat, y=new_df_1.OriginLong, size=10)\n",
    "#plt.ylabel('Longitude', fontsize=12)\n",
    "#plt.xlabel('Latitude', fontsize=12)\n",
    "#plt.show()\n",
    "#sns.despine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.replace(to_replace=df['scheduled_arrival'].dt.day, value=df['expected_arrival'].dt.day, inplace=True)\n",
    "\n",
    "#df['ScheduledArrivalTime'].apply(lambda x: x[0:2].replace('24', '00'))\n",
    "\n",
    "#examining the head of the 'expected_arrival' column.\n",
    "#print(df['expected_arrival'].head())\n",
    "\n",
    "#df['expected_arrival'].dt.day.value_counts()\n",
    "\n",
    "#examining the head of the 'scheduled_arrival' column.\n",
    "#print(df['scheduled_arrival'].head())\n",
    "\n",
    "#df['scheduled_arrival'].dt.day.value_counts()\n",
    "\n",
    "#dayVal = df['expected_arrival'].dt.day\n",
    "#print(type(dayVal))\n",
    "\n",
    "#df['scheduled_arrival'] = df['scheduled_arrival'].apply(lambda t: t.replace(day=Var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new features by converting strings to datetimes\n",
    "#df['expected_arrival'] = pd.to_datetime(df['ExpectedArrivalTime'], errors=\"coerce\")\n",
    "#df['scheduled_arrival'] = pd.to_datetime(df['ScheduledArrivalTime'], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correcting the year value in the two new feature columns\n",
    "#df['expected_arrival'] = df['expected_arrival'].apply(lambda t: t.replace(year=2017) if not pd.isnull(t) else pd.NaT)\n",
    "#df['scheduled_arrival'] = df['scheduled_arrival'].apply(lambda t: t.replace(year=2017) if not pd.isnull(t) else pd.NaT)\n",
    "\n",
    "#correcting the day value in the new feature columns\n",
    "#df['expected_arrival'] = df['expected_arrival'].apply(lambda t: t.replace(day=1) if not pd.isnull(t) else pd.NaT)\n",
    "#df['scheduled_arrival'] = df['scheduled_arrival'].apply(lambda t: t.replace(day=1) if not pd.isnull(t) else pd.NaT)\n",
    "\n",
    "#correcting the month value in the new feature columns\n",
    "#df['expected_arrival'] = df['expected_arrival'].apply(lambda t: t.replace(month=6) if not pd.isnull(t) else pd.NaT)\n",
    "#df['scheduled_arrival'] = df['scheduled_arrival'].apply(lambda t: t.replace(month=6) if not pd.isnull(t) else pd.NaT)\n",
    "#print(df['expected_arrival'])\n",
    "\n",
    "\n",
    "#df['delay_neg'] = pd.to_numeric(df['delay'], errors='coerce')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
